{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02285e6",
   "metadata": {
    "id": "a02285e6"
   },
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc5329",
   "metadata": {
    "id": "bdcc5329"
   },
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:50:51.756775Z",
     "iopub.status.busy": "2025-04-18T21:50:51.756565Z",
     "iopub.status.idle": "2025-04-18T21:52:28.896562Z",
     "shell.execute_reply": "2025-04-18T21:52:28.895717Z",
     "shell.execute_reply.started": "2025-04-18T21:50:51.756758Z"
    },
    "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl, evaluate, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.16.1\n",
      "Collecting nvidia-ml-py3\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: nvidia-ml-py3\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19173 sha256=c3669aa2332b8c861cef166ed55f4d22b56ed92257ab5e371e8aed24e728a38c\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
      "Successfully built nvidia-ml-py3\n",
      "Installing collected packages: nvidia-ml-py3\n",
      "Successfully installed nvidia-ml-py3-7.352.0\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.1\n",
      "    Uninstalling transformers-4.51.1:\n",
      "      Successfully uninstalled transformers-4.51.1\n",
      "Successfully installed transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate accelerate peft trl bitsandbytes\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:52:28.897790Z",
     "iopub.status.busy": "2025-04-18T21:52:28.897549Z",
     "iopub.status.idle": "2025-04-18T21:52:53.841253Z",
     "shell.execute_reply": "2025-04-18T21:52:53.840313Z",
     "shell.execute_reply.started": "2025-04-18T21:52:28.897756Z"
    },
    "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:52:41.104245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745013161.320016      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745013161.381253      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6e377",
   "metadata": {
    "id": "59d6e377"
   },
   "source": [
    "## Load Tokenizer and Preprocess Data\n",
    "\n",
    "To clean the dataset, we filter out very short headlines (less than 10 tokens) and extremely long ones (more than 512 tokens), which might cause instability during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:52:53.844292Z",
     "iopub.status.busy": "2025-04-18T21:52:53.843492Z",
     "iopub.status.idle": "2025-04-18T21:53:56.873854Z",
     "shell.execute_reply": "2025-04-18T21:53:56.873245Z",
     "shell.execute_reply.started": "2025-04-18T21:52:53.844257Z"
    },
    "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b71a73e2f04119b3caef9889078bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77edb40d7bd47cba3bf77a6d191c5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8b002b1fb401e920aa36af59951e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4174857977ad4e6cba37428eec353934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395c075b384649e887f69ef84a8d1d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6947534ce8854122bf153f1160c57595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e692ad49164d35b04b918e20d84004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd378d847cb44f9aa24a4eac52617b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884c2d559c1847a083b7b2bb1ed86db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e11774fe9d04a7babbdc0976b30f584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0639f01447e4557b8f80e931bf170a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de35456ae15341679070b40c296100e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = \"roberta-base\"\n",
    "dataset = load_dataset('ag_news', split='train')\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
    "dataset = dataset.filter(lambda x: 10 < len(x[\"text\"].split()) <= 512)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "num_labels = dataset.features['label'].num_classes\n",
    "id2label = {i: label for i, label in enumerate(dataset.features['label'].names)}\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a4c78",
   "metadata": {},
   "source": [
    "We load a pre-trained RoBERTa model for sequence classification with 4 output classes.\n",
    "\n",
    "Then, we apply LoRA (Low-Rank Adaptation) to freeze the model and inject lightweight trainable adapters into the attention mechanism:\n",
    "\n",
    "We adapt only query, key, and value projection matrices.\n",
    "\n",
    "r=6 controls the rank of the low-rank matrix.\n",
    "\n",
    "alpha=16 scales the adapter output.\n",
    "\n",
    "dropout=0.1 adds regularization.\n",
    "\n",
    "This greatly reduces the number of trainable parameters, staying under the 1M limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:55:42.462641Z",
     "iopub.status.busy": "2025-04-18T21:55:42.461877Z",
     "iopub.status.idle": "2025-04-18T21:55:42.707615Z",
     "shell.execute_reply": "2025-04-18T21:55:42.706872Z",
     "shell.execute_reply.started": "2025-04-18T21:55:42.462609Z"
    },
    "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model, num_labels=num_labels, id2label=id2label\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=6, \n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\", \"key\"],  \n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9278e0",
   "metadata": {},
   "source": [
    "##  Training Configuration\n",
    "We split our tokenized dataset into training and validation sets, using 640 samples for validation.\n",
    "\n",
    "We define training hyperparameters using TrainingArguments:\n",
    "\n",
    "4 epochs\n",
    "\n",
    "Batch sizes: 16 (train) and 64 (eval)\n",
    "\n",
    "Cosine learning rate decay with warmup\n",
    "\n",
    "Best model checkpoint is saved based on accuracy\n",
    "\n",
    "We also define a simple compute_metrics function that calculates accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7413430-be57-482b-856e-36bd4ba799df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:55:44.396090Z",
     "iopub.status.busy": "2025-04-18T21:55:44.395772Z",
     "iopub.status.idle": "2025-04-18T21:55:44.449254Z",
     "shell.execute_reply": "2025-04-18T21:55:44.448712Z",
     "shell.execute_reply.started": "2025-04-18T21:55:44.396064Z"
    },
    "id": "e7413430-be57-482b-856e-36bd4ba799df",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split = tokenized_dataset.train_test_split(test_size=640, seed=42)\n",
    "train_dataset = split['train']\n",
    "eval_dataset = split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:55:45.995236Z",
     "iopub.status.busy": "2025-04-18T21:55:45.994550Z",
     "iopub.status.idle": "2025-04-18T21:55:46.411739Z",
     "shell.execute_reply": "2025-04-18T21:55:46.411079Z",
     "shell.execute_reply.started": "2025-04-18T21:55:45.995211Z"
    },
    "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/1854385982.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": accuracy_score(pred.label_ids, preds)}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b848278",
   "metadata": {
    "id": "9b848278"
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:55:48.793188Z",
     "iopub.status.busy": "2025-04-18T21:55:48.792645Z",
     "iopub.status.idle": "2025-04-19T01:29:59.707613Z",
     "shell.execute_reply": "2025-04-19T01:29:59.706869Z",
     "shell.execute_reply.started": "2025-04-18T21:55:48.793167Z"
    },
    "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14920' max='14920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14920/14920 3:34:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.221683</td>\n",
       "      <td>0.923438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.209723</td>\n",
       "      <td>0.928125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.205723</td>\n",
       "      <td>0.926562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14920, training_loss=0.2992374527550255, metrics={'train_runtime': 12850.4997, 'train_samples_per_second': 37.149, 'train_steps_per_second': 1.161, 'total_flos': 8.418353115112325e+16, 'train_loss': 0.2992374527550255, 'epoch': 4.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183be7e-514f-4e64-a6f4-314a827e6be5",
   "metadata": {
    "id": "5183be7e-514f-4e64-a6f4-314a827e6be5"
   },
   "source": [
    "## Evaluate Finetuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e032c-4ef7-48dd-8d35-0e3e30a4a9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:29:59.709417Z",
     "iopub.status.busy": "2025-04-19T01:29:59.708969Z",
     "iopub.status.idle": "2025-04-19T01:30:06.336236Z",
     "shell.execute_reply": "2025-04-19T01:30:06.335445Z",
     "shell.execute_reply.started": "2025-04-19T01:29:59.709398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Final Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Trainable Parameters: 925444\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Evaluation:\")\n",
    "trainer.evaluate()\n",
    "\n",
    "trainable = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {trainable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038198cf-0953-47e7-bd47-b073d05f8378",
   "metadata": {
    "id": "038198cf-0953-47e7-bd47-b073d05f8378"
   },
   "source": [
    "### Performing Inference on Custom Input\n",
    "Uncomment following functions for running inference on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88ad420-3f46-4eff-9d71-0ce388163062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:30:06.337192Z",
     "iopub.status.busy": "2025-04-19T01:30:06.336972Z",
     "iopub.status.idle": "2025-04-19T01:30:06.341993Z",
     "shell.execute_reply": "2025-04-19T01:30:06.341026Z",
     "shell.execute_reply.started": "2025-04-19T01:30:06.337174Z"
    },
    "id": "f88ad420-3f46-4eff-9d71-0ce388163062",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    output = model(**inputs)\n",
    "\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "\n",
    "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:30:06.344057Z",
     "iopub.status.busy": "2025-04-19T01:30:06.343613Z",
     "iopub.status.idle": "2025-04-19T01:30:06.425167Z",
     "shell.execute_reply": "2025-04-19T01:30:06.424641Z",
     "shell.execute_reply.started": "2025-04-19T01:30:06.344039Z"
    },
    "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class: 1, Label: Sports, Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\n",
      "\n",
      " Class: 2, Label: Business, Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindlinand of ultra-cynics, are seeing green again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
    "classify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf",
   "metadata": {
    "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf"
   },
   "source": [
    "### Run Inference on eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:30:06.425947Z",
     "iopub.status.busy": "2025-04-19T01:30:06.425774Z",
     "iopub.status.idle": "2025-04-19T01:30:06.432496Z",
     "shell.execute_reply": "2025-04-19T01:30:06.431946Z",
     "shell.execute_reply.started": "2025-04-19T01:30:06.425933Z"
    },
    "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        inference_model: The model to evaluate.\n",
    "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
    "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
    "                         If False, only predictions will be returned.\n",
    "        batch_size (int): Batch size for inference.\n",
    "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True, returns a tuple (metrics, predictions)\n",
    "        If labelled is False, returns the predictions.\n",
    "    \"\"\"\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    if labelled:\n",
    "        metric = evaluate.load('accuracy')\n",
    "\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            references = batch[\"labels\"]\n",
    "            metric.add_batch(\n",
    "                predictions=predictions.cpu().numpy(),\n",
    "                references=references.cpu().numpy()\n",
    "            )\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        eval_metric = metric.compute()\n",
    "        print(\"Evaluation Metric:\", eval_metric)\n",
    "        return eval_metric, all_predictions\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:30:06.433481Z",
     "iopub.status.busy": "2025-04-19T01:30:06.433256Z",
     "iopub.status.idle": "2025-04-19T01:30:18.371947Z",
     "shell.execute_reply": "2025-04-19T01:30:18.371230Z",
     "shell.execute_reply.started": "2025-04-19T01:30:06.433461Z"
    },
    "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e9b2902c5c49dc82fed7dbac5a481e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:11<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metric: {'accuracy': 0.928125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, _ = evaluate_model(peft_model, eval_dataset, True, 8, data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203",
   "metadata": {
    "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203"
   },
   "source": [
    "### Run Inference on unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461de4a-c4bd-44a4-8528-7e131e64f25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:55:43.069517Z",
     "iopub.status.busy": "2025-04-19T01:55:43.069245Z",
     "iopub.status.idle": "2025-04-19T01:57:41.001874Z",
     "shell.execute_reply": "2025-04-19T01:57:41.000989Z",
     "shell.execute_reply.started": "2025-04-19T01:55:43.069495Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57a6d00bf264514b313fefa98800393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:51<00:00,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to inference_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unlabelled_dataset = pd.read_pickle(\"/kaggle/input/test-unlabelled-pkl/test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset\n",
    "preds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy() \n",
    "})\n",
    "df_output.to_csv(\"/kaggle/working/inference_output2.csv\", index=False)\n",
    "print(\"Inference complete. Predictions saved to inference_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba7fa5",
   "metadata": {},
   "source": [
    "#### Observations and Lessons\n",
    "Here are some insights from our experiments:\n",
    "\n",
    "r=6 and alpha=16 performed better than larger ranks which caused overfitting.\n",
    "\n",
    "Filtering out very short or very long inputs improved stability.\n",
    "\n",
    "The warmup ratio and cosine scheduler helped avoid early overfitting.\n",
    "\n",
    "Applying LoRA to feedforward layers violated the parameter budget.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7184780,
     "sourceId": 11465344,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7186402,
     "sourceId": 11467726,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
